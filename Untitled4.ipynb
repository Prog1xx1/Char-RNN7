{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93b8632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# pobieranie pliku z tekstami szekspira\n",
    "url = \"https://homl.info/shakespeare\"\n",
    "response = urllib.request.urlopen(url)\n",
    "data = response.read().decode()\n",
    "text = \"\".join(line for line in data if line not in string.punctuation) #.lower()\n",
    "\n",
    "# tworzenie słownika znaków\n",
    "all_characters = sorted(set(text))\n",
    "n_characters = len(all_characters)\n",
    "char_to_index = {ch: i for i, ch in enumerate(all_characters)}\n",
    "\n",
    "# definicja modelu CHAR-RNN\n",
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.rnn(input, hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.n_layers, 1, self.hidden_size)\n",
    "\n",
    "# przygotowanie danych uczących\n",
    "chunk_len = 200\n",
    "def random_chunk():\n",
    "    start_index = random.randint(0, len(text) - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return text[start_index:end_index]\n",
    "    \n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = char_to_index[string[c]]\n",
    "    return tensor\n",
    "\n",
    "def random_training_set():\n",
    "    chunk = random_chunk()\n",
    "    input = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return input, target\n",
    "\n",
    "# parametry modelu i uczenia\n",
    "n_epochs = 1000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "hidden_size = 100\n",
    "n_layers = 1\n",
    "lr = 0.005\n",
    "\n",
    "# inicjalizacja modelu i optymalizatora\n",
    "model = CharRNN(n_characters, hidden_size, n_characters, n_layers)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# funkcja treningowa\n",
    "def train(input, target):\n",
    "    hidden = model.init_hidden()\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    for c in range(chunk_len - 1):\n",
    "        output, hidden = model(input[c], hidden)\n",
    "        loss += criterion(output, target[c].unsqueeze(0))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item() / (chunk_len - 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62e6127c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_index ['t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c30fae67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.2278\n",
      "Epoch [200/1000], Loss: 0.2137\n",
      "Epoch [300/1000], Loss: 0.2079\n",
      "Epoch [400/1000], Loss: 0.2005\n",
      "Epoch [500/1000], Loss: 0.1955\n",
      "Epoch [600/1000], Loss: 0.1976\n",
      "Epoch [700/1000], Loss: 0.1945\n",
      "Epoch [800/1000], Loss: 0.1962\n",
      "Epoch [900/1000], Loss: 0.1979\n",
      "Epoch [1000/1000], Loss: 0.1895\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_samples):\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# implementacja prostego czatbota\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchatbot\u001b[39m():\n",
      "Cell \u001b[1;32mIn[6], line 24\u001b[0m, in \u001b[0;36mgenerate\u001b[1;34m(start_string, max_length)\u001b[0m\n\u001b[0;32m     22\u001b[0m output_str \u001b[38;5;241m=\u001b[39m start_string\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_length):\n\u001b[1;32m---> 24\u001b[0m     output, hidden \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, hidden)\n\u001b[0;32m     25\u001b[0m     output_dist \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdiv(temperature)\u001b[38;5;241m.\u001b[39mexp()\n\u001b[0;32m     26\u001b[0m     top_i \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmultinomial(output_dist, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "# trening modelu\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(*random_training_set())\n",
    "    loss_avg += loss\n",
    "    if epoch % print_every == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch, n_epochs, loss_avg / print_every))\n",
    "        loss_avg = 0\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0\n",
    "\n",
    "# funkcja generująca tekst na podstawie modelu\n",
    "max_length = 1000\n",
    "temperature = 0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ff7d673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thehe IaaEahawtohaawoohiIhooiiwIooaoaoaaoaoaIaIaoIoaoIaaaoaaaIahIaahoaaIiaiaaoaoaaoooroaiaoIoaapoooaIah\n",
      "TheheraahaoaEooooaaooaaaaIahohaoEIoaaaiooaaaaoiaihhEohiiiahoaaaIEIaooahooaiahaahIhooIoohaaoIaaoaoaoaaaa\n",
      "ThehergaaaaIahEaoIoaoahihaoooohohhoiIiaiahhaaaoiaalaIaaaoohEaIohaoaoaaaaaoIoaohoaooaaaEPiIwacaaoiorIaao\n",
      "TheIe maiaiaopoIoaaaoIaoIIhhaawaaaoaoahoaEoaoaaoiaoaooaaooaaaaaawEapoIaaIooaaEaaaIaaawoaaaIaIaaooohoaah\n",
      "TheoerchahaiaoaaioaaoaoaIoooIaIohoooaahoowIoawaoawhaooaoaaaihahaaEoioiuaIaaaahaaioaoooaohhhaaaEoaaoaaaE\n",
      "Hello, I am a chatbot trained on Shakespeare's texts. Ask me a question or say \"exit\" to quit.\n",
      "> how are you\n",
      "how are youou m e aou ahiyaoaioloaaaoaaIiaaoIoaaaioIohoIaaEoooraIiaaoaahaaaahooiahhhaaaaaIaaoaoohooaoIhaoahaaao\n",
      "> ssd\n",
      "ssd e woaoaaaiooaooooahaaawahIaowaawhhaaahKaaohahIIiooaoohaahuohaooiiarahIohaoioaawaoaaaaoaaaooaaaahaoo\n",
      "> exit\n"
     ]
    }
   ],
   "source": [
    "def generate(start_string='The', max_length=100):\n",
    "    with torch.no_grad():\n",
    "        input_str = start_string.ljust(max_length)\n",
    "        hidden = model.init_hidden()\n",
    "        output_str = start_string\n",
    "        for i in range(max_length):\n",
    "            input = char_tensor(input_str[i:i+1])\n",
    "            output, hidden = model(input, hidden)\n",
    "            output_dist = output.data.view(-1).div(temperature).exp()\n",
    "            top_i = torch.multinomial(output_dist, 1)[0]\n",
    "            predicted_char = all_characters[top_i]\n",
    "            output_str += predicted_char\n",
    "        return output_str\n",
    "\n",
    "# generowanie tekstu z losowym początkiem\n",
    "n_samples = 5\n",
    "for i in range(n_samples):\n",
    "    print(generate())\n",
    "\n",
    "# implementacja prostego czatbota\n",
    "def chatbot():\n",
    "    print('Hello, I am a chatbot trained on Shakespeare\\'s texts. Ask me a question or say \"exit\" to quit.')\n",
    "    while True:\n",
    "        start_string = input('> ')\n",
    "        if start_string.lower() == 'exit':\n",
    "            break\n",
    "        output_str = generate(start_string=start_string, max_length=100)\n",
    "        print(output_str)\n",
    "\n",
    "# uruchomienie czatbota\n",
    "chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a3d620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
